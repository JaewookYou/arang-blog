#!/usr/bin/env python3
"""
í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ê³  ë‹¤ìš´ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import re
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import hashlib
import time

# í‹°ìŠ¤í† ë¦¬ ê¸€ ëª©ë¡
POSTS = {
    "posts": [
        ("72", "selenium-v4-error-fix"),
        ("69", "fiddler-https-certificate-error"),
        ("56", "jsp-commons-fileupload-waf-bypass"),
        ("35", "csp-bypass-techniques"),
        ("34", "ecmascript-xss-bypass"),
        ("31", "xss-bypass-waf-filtering"),
        ("7", "sql-injection-bypass-tips"),
    ],
    "writeups": [
        ("71", "wacon-2022-kuncelan"),
        ("70", "codegate-2022-web-blockchain"),
        ("68", "fiesta-2021-chatservice"),
        ("67", "whitehat-2021-web"),
        ("66", "cyberwarfare-2020-vaccine-paper"),
        ("65", "cyberwarfare-2020-intranet"),
        ("64", "tsg-ctf-2020-slick-logger"),
        ("63", "defenit-ctf-2020-osint"),
        ("33", "hacklu-2019-rpdg"),
        ("6", "asis-ctf-2018-neighbour"),
    ]
}

BASE_URL = "https://ar9ang3.tistory.com/"
CONTENT_DIR = "/home/arang/web/blog/content"
PUBLIC_DIR = "/home/arang/web/blog/public/images"

def get_images_from_tistory(post_id):
    """í‹°ìŠ¤í† ë¦¬ ê¸€ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
    url = f"{BASE_URL}{post_id}"
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë³¸ë¬¸ ì˜ì—­ ì°¾ê¸°
        content_area = soup.find('div', class_='entry-content') or \
                       soup.find('div', class_='tt_article_useless_p_margin') or \
                       soup.find('article') or \
                       soup.find('div', class_='area_view')
        
        if not content_area:
            # ì „ì²´ í˜ì´ì§€ì—ì„œ ì´ë¯¸ì§€ ì°¾ê¸°
            content_area = soup
        
        images = []
        for img in content_area.find_all('img'):
            src = img.get('src') or img.get('data-src') or img.get('data-lazy-src')
            if src:
                # ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
                if src.startswith('//'):
                    src = 'https:' + src
                elif src.startswith('/'):
                    src = urljoin(BASE_URL, src)
                
                # í‹°ìŠ¤í† ë¦¬ CDN ì´ë¯¸ì§€ë§Œ ì¶”ì¶œ
                if 'tistory' in src or 'daumcdn' in src or 'kakaocdn' in src:
                    images.append(src)
        
        return images
    except Exception as e:
        print(f"[!] Error fetching {url}: {e}")
        return []

def download_image(url, save_dir, prefix):
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    try:
        # íŒŒì¼ëª… ìƒì„± (URL í•´ì‹œ + ì›ë³¸ í™•ì¥ì)
        parsed = urlparse(url)
        ext = os.path.splitext(parsed.path)[1] or '.png'
        if '?' in ext:
            ext = ext.split('?')[0]
        if not ext or len(ext) > 5:
            ext = '.png'
        
        filename = f"{prefix}_{hashlib.md5(url.encode()).hexdigest()[:8]}{ext}"
        filepath = os.path.join(save_dir, filename)
        
        if os.path.exists(filepath):
            print(f"  [=] Already exists: {filename}")
            return filename
        
        response = requests.get(url, timeout=30, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': BASE_URL
        })
        response.raise_for_status()
        
        with open(filepath, 'wb') as f:
            f.write(response.content)
        
        print(f"  [+] Downloaded: {filename}")
        return filename
    except Exception as e:
        print(f"  [!] Error downloading {url}: {e}")
        return None

def update_markdown_with_images(mdx_path, category, slug, images_info):
    """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì— ì´ë¯¸ì§€ ì¶”ê°€"""
    if not images_info:
        return
    
    try:
        with open(mdx_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ì´ë¯¸ì§€ ì„¹ì…˜ ì¶”ê°€ (ë³¸ë¬¸ ì‹œì‘ ì§í›„, ì²« ë²ˆì§¸ ## ì „ì—)
        image_md = "\n\n## ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€\n\n"
        for idx, (url, filename) in enumerate(images_info, 1):
            image_path = f"/images/{category}/{filename}"
            image_md += f"![Image {idx}]({image_path})\n\n"
        
        # ì²« ë²ˆì§¸ ## ì°¾ì•„ì„œ ê·¸ ì•ì— ì‚½ì…
        match = re.search(r'\n## ', content)
        if match:
            insert_pos = match.start()
            new_content = content[:insert_pos] + image_md + content[insert_pos:]
        else:
            # ## ì—†ìœ¼ë©´ ë§¨ ëì— ì¶”ê°€
            new_content = content + image_md
        
        with open(mdx_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print(f"  [*] Updated: {mdx_path}")
    except Exception as e:
        print(f"  [!] Error updating {mdx_path}: {e}")

def main():
    total_images = 0
    
    for category, posts in POSTS.items():
        print(f"\n{'='*50}")
        print(f"Processing {category.upper()}")
        print('='*50)
        
        save_dir = os.path.join(PUBLIC_DIR, category)
        os.makedirs(save_dir, exist_ok=True)
        
        for post_id, slug in posts:
            print(f"\n[{post_id}] {slug}")
            
            # ì´ë¯¸ì§€ URL ì¶”ì¶œ
            images = get_images_from_tistory(post_id)
            print(f"  Found {len(images)} images")
            
            if not images:
                continue
            
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            downloaded = []
            for img_url in images:
                filename = download_image(img_url, save_dir, slug)
                if filename:
                    downloaded.append((img_url, filename))
                time.sleep(0.3)  # Rate limiting
            
            # ë§ˆí¬ë‹¤ìš´ ì—…ë°ì´íŠ¸
            mdx_path = os.path.join(CONTENT_DIR, category, f"{slug}.mdx")
            if os.path.exists(mdx_path):
                update_markdown_with_images(mdx_path, category, slug, downloaded)
            
            total_images += len(downloaded)
    
    print(f"\n{'='*50}")
    print(f"Total images downloaded: {total_images}")
    print('='*50)

if __name__ == "__main__":
    main()
